import java.sql.Timestamp

import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder
import org.apache.spark.sql.functions._


case class Transaction(details: String, amount: Int, ts: Timestamp)
case class SumAmounts(beneficiary: String, amount: BigInt)
case class PayerBenSet(amount: Int, ts: Timestamp, payer: String, beneficiary: String)


object SparkTranformationEncoder {

  def sumAmounts(transaction: Dataset[PayerBenSet]): Dataset[SumAmounts] = {
    implicit val enc: ExpressionEncoder[SumAmounts] = ExpressionEncoder[SumAmounts]
    transaction.groupBy("beneficiary").agg(sum("amount") as "amount").as[SumAmounts]
  }


  def splitColumnOnRegex(transaction: Dataset[Transaction]): Dataset[PayerBenSet] = {
    implicit val enc: ExpressionEncoder[PayerBenSet] = ExpressionEncoder[PayerBenSet]
    val payerBen: Dataset[PayerBenSet] = transaction
      .withColumn("payer", regexp_extract(col("details"), "paid by ([A-Z])", 1))
      .withColumn("beneficiary", regexp_extract(col("details"), "to ([A-Z])", 1))
      .as[PayerBenSet]
    payerBen
  }

  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder().appName("SparkTransaction").master("local").getOrCreate()
    import spark.implicits._
    val dfTransactions: Dataset[Transaction] = Seq(
      Transaction("paid by A to X", 100, Timestamp.valueOf("2018-01-05 08:00:00")),
      Transaction("paid by B to X", 10, Timestamp.valueOf("2018-01-05 11:00:00")),
      Transaction("paid by C to Y", 15, Timestamp.valueOf("2018-01-06 12:00:00")),
      Transaction("paid by D to Z", 50, Timestamp.valueOf("2018-01-06 15:00:00")),
      Transaction("paid by D to Z", 40, Timestamp.valueOf("2018-01-06 15:00:00"))
    ).toDS


    //sumAmounts(dfTransactions)
    //    splitColumnOnRegex(dfTransactions)
    dfTransactions
      .transform(splitColumnOnRegex)
      .transform(sumAmounts).show()
  }
}
